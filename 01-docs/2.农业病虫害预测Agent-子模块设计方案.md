# 农业病虫害预测Agent - 子模块设计方案

## 模块一:环境感知Agent

### 1. 业务设计

**业务流程:**
1. 定时采集农田环境数据(气象、土壤、作物)
2. 多源数据融合 → 整合IoT传感器、卫星遥感、无人机数据
3. 数据质量控制 → 异常值检测、缺失值填充、传感器校准
4. 特征提取 → 提取温度、湿度、pH值、NDVI等关键特征
5. 数据存储与索引 → 高效存储与快速检索
6. 实时数据推送 → 向预测Agent推送最新数据

**功能需求:**
- 多源数据采集(IoT传感器、气象站、卫星、无人机)
- 数据质量控制(异常检测、缺失值处理)
- 传感器自校准(基于历史数据与邻居传感器)
- 数据融合算法(时空融合、多模态融合)
- 特征工程(时序特征、空间特征、交互特征)
- 实时数据流处理
- 历史数据归档
- 数据可视化(实时监控大屏)

**使用场景:**
- 日常环境监控:实时监测农田环境变化
- 病虫害预警基础:为预测模型提供输入数据
- 精准农业指导:基于环境数据优化农事操作
- 决策支持:帮助农户做出种植与灌溉决策
- 灾害预警:极端天气提前预警

### 2. 应用设计

**架构组成:**
```
环境感知Agent
├── 数据采集层
│   ├── IoT传感器接口(土壤、气象、作物)
│   ├── 气象站API接口
│   ├── 卫星遥感接口
│   └── 无人机数据接口
├── 数据处理层
│   ├── 数据质量检查模块
│   ├── 异常检测模块
│   ├── 传感器校准模块
│   └── 数据融合模块
├── 特征工程层
│   ├── 时序特征提取
│   ├── 空间特征提取
│   ├── 交互特征生成
│   └── 特征选择模块
└── 数据服务层
    ├── 实时数据API
    ├── 历史数据API
    ├── 数据可视化服务
    └── 数据推送服务
```

**接口规范:**
- `GET /api/environment/realtime` - 获取实时环境数据
  - 请求: `{fieldId: "xxx", sensors: ["temperature", "humidity"]}`
  - 响应: `{timestamp, temperature, humidity, soil_moisture, ...}`
- `GET /api/environment/history` - 获取历史数据
  - 请求: `{fieldId: "xxx", timeRange: {start, end}, sensors: []}`
  - 响应: `{data: [{timestamp, ...}]}`
- `POST /api/environment/quality-check` - 数据质量检查
  - 请求: `{data: []}`
  - 响应: `{qualityScore: 0.95, anomalies: []}`
- `GET /api/environment/features` - 获取特征数据
  - 请求: `{fieldId: "xxx", date: "2026-02-15"}`
  - 响应: `{features: {temp_avg, temp_std, humidity_trend, ...}}`

**交互逻辑:**
1. 通过MQTT协议接收IoT传感器数据
2. 使用Apache Kafka进行实时数据流处理
3. 通过MCP协议与病虫害预测Agent交互
4. 使用Redis缓存实时数据
5. 通过WebSocket推送实时数据至前端

### 3. 数据设计

**数据结构:**
```sql
-- 农田表
CREATE TABLE field (
  id VARCHAR(64) PRIMARY KEY,
  name VARCHAR(255),
  owner VARCHAR(255),
  location GEOGRAPHY(POINT, 4326),
  area DECIMAL(10,2),  -- 面积(亩)
  crop_type VARCHAR(100),
  planting_date DATE,
  expected_harvest_date DATE,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 传感器表
CREATE TABLE sensor (
  id VARCHAR(64) PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  sensor_type VARCHAR(50),  -- temperature/humidity/soil_moisture/NDVI
  model VARCHAR(100),
  location GEOGRAPHY(POINT, 4326),
  installation_date DATE,
  calibration_date DATE,
  status VARCHAR(20),  -- active/maintenance/offline
  metadata JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 环境数据表(时序数据)
CREATE TABLE environment_data (
  id SERIAL PRIMARY KEY,
  sensor_id VARCHAR(64) REFERENCES sensor(id),
  timestamp TIMESTAMP NOT NULL,
  temperature DECIMAL(5,2),
  humidity DECIMAL(5,2),
  soil_moisture DECIMAL(5,2),
  soil_ph DECIMAL(4,2),
  soil_temperature DECIMAL(5,2),
  ndvi DECIMAL(4,2),
  wind_speed DECIMAL(5,2),
  precipitation DECIMAL(5,2),
  data_quality_score DECIMAL(3,2),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 遥感数据表
CREATE TABLE remote_sensing_data (
  id SERIAL PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  satellite VARCHAR(50),
  image_date DATE,
  cloud_coverage DECIMAL(3,2),
  resolution DECIMAL(6,2),  -- 空间分辨率(米)
  ndvi_mean DECIMAL(4,2),
  ndvi_std DECIMAL(4,2),
  image_path TEXT,  -- S3路径
  metadata JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 数据质量日志表
CREATE TABLE data_quality_log (
  id SERIAL PRIMARY KEY,
  sensor_id VARCHAR(64) REFERENCES sensor(id),
  timestamp TIMESTAMP,
  quality_issue_type VARCHAR(100),  -- outlier/missing/calibration_drift
  description TEXT,
  severity VARCHAR(20),  -- low/medium/high
  auto_corrected BOOLEAN,
  corrected_value DECIMAL(10,2),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 特征数据表
CREATE TABLE feature_data (
  id SERIAL PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  date DATE,
  feature_name VARCHAR(100),
  feature_value DECIMAL(10,4),
  feature_source VARCHAR(50),  -- sensor/remote_sensing/calculated
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**存储方案:**
- **时序数据库**: InfluxDB存储高频传感器数据
- **关系型数据库**: PostgreSQL存储传感器元数据与特征数据
- **对象存储**: S3存储遥感影像与原始数据
- **缓存**: Redis缓存实时数据
- **空间数据库**: PostGIS扩展存储地理位置信息

**数据处理流程:**
1. 数据采集 → 从IoT传感器、气象站、卫星等多源采集数据
2. 数据验证 → 验证数据格式与范围
3. 质量检查 → 异常值检测、缺失值检测、传感器故障检测
4. 数据校准 → 基于历史数据与邻居传感器进行校准
5. 数据融合 → 融合多源数据,填充缺失值
6. 特征提取 → 提取时序特征、空间特征、交互特征
7. 数据存储 → 分层存储(实时数据、历史数据、特征数据)
8. 数据推送 → 实时推送至预测Agent

### 4. 技术设计

**技术选型:**
- **IoT协议**: MQTT (传感器数据传输)
- **流处理**: Apache Kafka + Apache Flink (实时数据处理)
- **时序数据库**: InfluxDB (高频数据存储)
- **关系数据库**: PostgreSQL + PostGIS (元数据存储)
- **对象存储**: AWS S3 / 阿里云OSS (遥感影像)
- **缓存**: Redis (实时数据缓存)
- **空间计算**: PostGIS (空间数据分析)
- **异常检测**: Isolation Forest, DBSCAN
- **数据融合**: Kalman Filter, Dempster-Shafer理论
- **消息队列**: RabbitMQ (异步任务)

**实现方法:**
```python
# 环境感知核心逻辑
class EnvironmentPerception:
    def __init__(self):
        self.influx_client = InfluxDBClient()
        self.postgres = PostgresClient()
        self.kafka_consumer = KafkaConsumer()
        self.redis_client = RedisClient()

    async def collect_sensor_data(self):
        """采集传感器数据"""
        messages = self.kafka_consumer.consume('sensor-data')
        for msg in messages:
            # 数据验证
            validated = self.validate_data(msg)
            if not validated['valid']:
                self.log_quality_issue(msg, validated['reason'])
                continue
            # 异常检测
            is_anomaly = self.detect_anomaly(msg)
            if is_anomaly:
                # 尝试校准
                corrected = self.calibrate_sensor(msg)
                if corrected['success']:
                    msg = corrected['data']
            # 存储数据
            await self.store_data(msg)
            # 更新缓存
            self.redis_client.set(f'sensor:{msg["sensor_id"]}:latest', msg)
            # 推送至预测Agent
            await self.push_to_prediction_agent(msg)

    def detect_anomaly(self, data):
        """异常检测"""
        # 从历史数据学习正常模式
        historical_data = self.get_historical_data(data['sensor_id'], days=30)
        model = IsolationForest()
        model.fit(historical_data)
        anomaly_score = model.score_samples([data['value']])
        return anomaly_score[0] < -0.5

    def calibrate_sensor(self, data):
        """传感器校准"""
        # 基于邻居传感器校准
        neighbors = self.get_neighbor_sensors(data['sensor_id'])
        neighbor_values = self.get_neighbor_values(neighbors, data['timestamp'])
        if len(neighbor_values) > 0:
            calibrated_value = np.mean(neighbor_values)
            return {
                'success': True,
                'data': {
                    **data,
                    'value': calibrated_value,
                    'calibrated': True
                }
            }
        return {'success': False}

    def extract_features(self, field_id, date):
        """特征提取"""
        # 获取原始数据
        sensor_data = self.get_sensor_data(field_id, date)
        # 时序特征
        features = {
            'temp_avg': np.mean(sensor_data['temperature']),
            'temp_std': np.std(sensor_data['temperature']),
            'temp_trend': self.calculate_trend(sensor_data['temperature']),
            'humidity_avg': np.mean(sensor_data['humidity']),
            'soil_moisture_avg': np.mean(sensor_data['soil_moisture']),
            # 空间特征
            'temp_spatial_var': self.calculate_spatial_variance(sensor_data['temperature']),
            # 交互特征
            'temp_humidity_corr': np.corrcoef(sensor_data['temperature'],
                                              sensor_data['humidity'])[0,1]
        }
        return features
```

**性能指标:**
- 数据采集延迟: < 1s
- 数据处理吞吐量: > 10,000 条/秒
- 异常检测准确率: > 90%
- 传感器校准准确率: > 85%
- 数据可用性: > 99.5%
- 数据存储扩展性: 支持100万+传感器
- 特征提取响应时间: < 5s

---

## 模块二:病虫害预测Agent

### 1. 业务设计

**业务流程:**
1. 接收环境感知Agent推送的实时特征数据
2. 加载农耕大模型1.0 → 多模态模型(图像+时序+空间)
3. 病虫害识别 → 基于作物图像与环境数据识别病虫害
4. 发生概率预测 → 预测未来7-30天病虫害发生概率
5. 风险等级评估 → 低/中/高风险
6. 预警推送 → 向农户/农场主推送预警信息
7. 历史回测 → 定期验证模型预测准确性

**功能需求:**
- 病虫害图像识别(常见病虫害500+种)
- 病虫害发生概率预测(7天/14天/30天)
- 风险等级评估(低/中/高)
- 多模态模型融合(图像+环境+时序)
- 模型实时更新(在线学习)
- 预测不确定性量化
- 预警推送(SMS/微信/APP)
- 历史回测与模型评估

**使用场景:**
- 日常病虫害预警:提前预防病虫害发生
- 施药决策支持:指导何时施药、施何种药
- 种植决策:选择抗病虫害品种
- 农业保险:为保险理赔提供依据
- 政府决策:区域病虫害联防联控

### 2. 应用设计

**架构组成:**
```
病虫害预测Agent
├── 模型层
│   ├── 图像识别模型(YOLOv8/EfficientNet)
│   ├── 时序预测模型(LSTM/Transformer)
│   ├── 多模态融合模型
│   └── 农耕大模型1.0接口
├── 预测层
│   ├── 病虫害识别模块
│   ├── 发生概率预测模块
│   ├── 风险评估模块
│   └── 不确定性量化模块
├── 推理服务层
│   ├── 批量推理服务
│   ├── 实时推理服务
│   └── 模型版本管理
└── 应用服务层
    ├── 预警推送服务
    ├── 预测API服务
    ├── 可视化服务
    └── 报告生成服务
```

**接口规范:**
- `POST /api/prediction/identify` - 病虫害识别
  - 请求: `{image: "base64", cropType: "rice", location: {lat, lng}}`
  - 响应: `{disease: "rice_blast", confidence: 0.95, severity: "high"}`
- `POST /api/prediction/probability` - 发生概率预测
  - 请求: `{fieldId: "xxx", horizon: 7}`
  - 响应: `{probabilities: [{disease, probability, riskLevel, peakDate}]}`
- `GET /api/prediction/alert` - 获取预警
  - 请求: `{fieldId: "xxx", riskLevel: ["high", "medium"]}`
  - 响应: `{alerts: [{disease, riskLevel, actionNeeded}]}`
- `POST /api/prediction/backtest` - 历史回测
  - 请求: `{modelVersion: "v1.2", timeRange: {start, end}}`
  - 响应: `{accuracy: 0.87, precision: 0.85, recall: 0.82}`

**交互逻辑:**
1. 通过MCP协议接收环境感知Agent推送的特征数据
2. 使用TensorFlow Serving进行模型推理
3. 通过消息队列异步处理预测任务
4. 通过推送服务发送预警信息

### 3. 数据设计

**数据结构:**
```sql
-- 病虫害表
CREATE TABLE pest_disease (
  id VARCHAR(64) PRIMARY KEY,
  name VARCHAR(255),
  scientific_name VARCHAR(255),
  crop_type VARCHAR(100),  -- rice/wheat/corn/vegetable
  disease_type VARCHAR(50),  -- fungal/bacterial/viral/insect
  severity_levels JSONB,  -- {low: {symptoms, damage}, medium: {}, high: {}}
  control_methods JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 预测结果表
CREATE TABLE prediction_result (
  id SERIAL PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  pest_disease_id VARCHAR(64) REFERENCES pest_disease(id),
  prediction_date DATE,
  forecast_horizon INTEGER,  -- 预测天数
  occurrence_probability DECIMAL(5,4),
  risk_level VARCHAR(20),  -- low/medium/high
  peak_date DATE,  -- 预计峰值日期
  confidence DECIMAL(3,2),
  uncertainty_score DECIMAL(3,2),
  model_version VARCHAR(50),
  input_features JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 预警记录表
CREATE TABLE alert_record (
  id SERIAL PRIMARY KEY,
  prediction_id INTEGER REFERENCES prediction_result(id),
  alert_time TIMESTAMP,
  alert_level VARCHAR(20),  -- info/warning/critical
  alert_channel VARCHAR(50),  -- SMS/wechat/app/email
  recipients JSONB,
  message_content TEXT,
  acknowledged BOOLEAN,
  acknowledge_time TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 图像数据表
CREATE TABLE pest_image (
  id VARCHAR(64) PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  pest_disease_id VARCHAR(64) REFERENCES pest_disease(id),
  image_date DATE,
  image_path TEXT,  -- S3路径
  image_embedding JSONB,  -- 特征向量
  label VARCHAR(255),  -- 人工标注标签
  label_confidence DECIMAL(3,2),
  model_prediction JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 模型评估表
CREATE TABLE model_evaluation (
  id SERIAL PRIMARY KEY,
  model_version VARCHAR(50),
  evaluation_date DATE,
  accuracy DECIMAL(4,3),
  precision DECIMAL(4,3),
  recall DECIMAL(4,3),
  f1_score DECIMAL(4,3),
  auc DECIMAL(4,3),
  test_dataset_size INTEGER,
  evaluation_notes TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**存储方案:**
- **关系型数据库**: PostgreSQL存储预测结果、预警记录
- **向量数据库**: Milvus存储图像embedding向量
- **对象存储**: S3存储病虫害图像
- **时序数据库**: InfluxDB存储预测结果时序数据
- **缓存**: Redis缓存高频查询的预测结果

**数据处理流程:**
1. 接收输入 → 接收环境特征与作物图像
2. 图像识别 → 识别当前病虫害类型与严重程度
3. 特征融合 → 融合图像特征与环境特征
4. 概率预测 → 预测未来病虫害发生概率
5. 风险评估 → 评估风险等级并确定峰值时间
6. 不确定性量化 → 计算预测的不确定性
7. 预警判断 → 根据风险等级决定是否预警
8. 结果存储 → 存储预测结果与预警记录

### 4. 技术设计

**技术选型:**
- **深度学习框架**: PyTorch 2.0 / TensorFlow
- **图像识别**: YOLOv8 (目标检测), EfficientNet (图像分类)
- **时序预测**: LSTM, Transformer, Temporal Fusion Transformer
- **多模态融合**: CLIP, Cross-Attention机制
- **模型部署**: TensorFlow Serving, TorchServe
- **向量数据库**: Milvus (图像检索)
- **特征存储**: Redis (特征缓存)
- **消息队列**: Apache Kafka (异步推理)
- **监控**: Prometheus + Grafana (模型监控)

**实现方法:**
```python
# 病虫害预测核心逻辑
class PestDiseasePredictor:
    def __init__(self):
        self.image_model = self.load_image_model('yolov8_pest')
        self.time_series_model = self.load_time_series_model('lstm_prediction')
        self.fusion_model = self.load_fusion_model('multimodal_fusion')
        self.risk_assessor = RiskAssessor()

    async def predict_pest_disease(self, field_id, horizon=7):
        """预测病虫害"""
        # 获取输入数据
        features = await self.get_environment_features(field_id)
        images = await self.get_crop_images(field_id)
        # 图像识别
        image_features = self.extract_image_features(images)
        pest_detections = self.image_model.detect(images)
        # 时序预测
        time_series_features = self.extract_time_series_features(features)
        probability = self.time_series_model.predict(time_series_features)
        # 多模态融合
        fused_features = self.fusion_model.fuse(image_features, time_series_features)
        final_probability = self.fusion_model.predict(fused_features)
        # 风险评估
        risk_level = self.risk_assessor.assess(final_probability)
        peak_date = self.predict_peak_date(final_probability)
        # 不确定性量化
        uncertainty = self.quantify_uncertainty(final_probability, features)
        return {
            'disease': pest_detections[0]['class'],
            'probability': final_probability,
            'risk_level': risk_level,
            'peak_date': peak_date,
            'confidence': 1 - uncertainty,
            'uncertainty': uncertainty
        }

    def extract_image_features(self, images):
        """提取图像特征"""
        features = []
        for image in images:
            feature = self.image_model.extract_features(image)
            features.append(feature)
        return np.mean(features, axis=0)

    def predict_peak_date(self, probability_sequence):
        """预测峰值日期"""
        peak_index = np.argmax(probability_sequence)
        current_date = datetime.now().date()
        peak_date = current_date + timedelta(days=peak_index)
        return peak_date

    def quantify_uncertainty(self, prediction, features):
        """量化不确定性"""
        # Monte Carlo Dropout
        mc_samples = []
        for _ in range(30):
            sample = self.time_series_model.predict(features, training=True)
            mc_samples.append(sample)
        mc_samples = np.array(mc_samples)
        uncertainty = np.std(mc_samples, axis=0).mean()
        return uncertainty

    def online_learning(self, new_data):
        """在线学习更新模型"""
        # 增量学习
        self.time_series_model.partial_fit(new_data['features'], new_data['labels'])
        # 定期全量更新
        if self.should_full_update():
            self.full_update_model()
```

**性能指标:**
- 图像识别准确率: > 90%
- 图像识别响应时间: < 500ms
- 发生概率预测准确率: > 85%
- 预测响应时间: < 2s
- 风险评估准确率: > 80%
- 预警推送延迟: < 5min
- 模型更新频率: 每周
- 系统可用性: > 99.5%

---

## 模块三:精准防控Agent

### 1. 业务设计

**业务流程:**
1. 接收病虫害预测Agent的预警信息
2. 病虫害诊断 → 确认病虫害类型与严重程度
3. 防控方案生成 → 基于知识库生成多种防控方案
4. 多目标优化 → 平衡防控效果、成本、环境影响
5. 方案评估 → 评估各方案的综合得分
6. 最佳方案推荐 → 推荐最优防控方案
7. 执行跟踪 → 跟踪防控效果并优化方案

**功能需求:**
- 病虫害诊断知识库(500+种病虫害)
- 防控方案生成(化学防治、生物防治、物理防治、综合防治)
- 农药推荐(基于农药数据库与法规)
- 用量计算(基于病虫害严重程度与作物面积)
- 施药时机推荐(基于天气预报与病虫害周期)
- 成本估算(农药成本、人工成本、设备成本)
- 环境影响评估(土壤、水源、非靶标生物)
- 多目标优化(效果、成本、环境影响)
- 防控效果跟踪

**使用场景:**
- 病虫害爆发应对:快速生成最优防控方案
- 日常预防性防治:根据预测提前预防
- 绿色农业:推荐低毒、环保的防控方案
- 政府监管:确保农药使用符合法规要求
- 成本优化:帮助农户降低防治成本

### 2. 应用设计

**架构组成:**
```
精准防控Agent
├── 知识库层
│   ├── 病虫害知识库
│   ├── 农药数据库
│   ├── 防控方法库
│   └── 法规数据库
├── 方案生成层
│   ├── 诊断模块
│   ├── 方案生成引擎
│   ├── 用量计算模块
│   └── 时机推荐模块
├── 优化决策层
│   ├── 多目标优化模块
│   ├── 成本估算模块
│   ├── 环境评估模块
│   └── 方案评估模块
└── 应用服务层
    ├── 方案推荐API
    ├── 农药合规检查API
    ├── 防控效果跟踪API
    └── 可视化服务
```

**接口规范:**
- `POST /api/control/generate-schemes` - 生成防控方案
  - 请求: `{fieldId: "xxx", disease: "rice_blast", severity: "high", preferences: {}}`
  - 响应: `{schemes: [{type, chemicals, dosage, cost, environmentalImpact}]}`
- `POST /api/control/optimize` - 多目标优化
  - 请求: `{schemes: [], objectives: ["effectiveness", "cost", "environment"], weights: {}}`
  - 响应: `{optimalScheme: {}, ranking: []}`
- `POST /api/control/check-compliance` - 农药合规检查
  - 请求: `{chemicals: [], region: "Guangdong"}`
  - 响应: `{compliant: true, violations: []}`
- `POST /api/control/track-effectiveness` - 跟踪防控效果
  - 请求: `{fieldId: "xxx", schemeId: "xxx"}`
  - 响应: `{effectiveness: 0.92, cost: 1200, notes: ""}`

**交互逻辑:**
1. 通过MCP协议接收病虫害预测Agent的预警
2. 使用知识图谱进行方案推荐
3. 通过MCP协议调用外部农药数据库API
4. 使用优化算法进行多目标决策

### 3. 数据设计

**数据结构:**
```sql
-- 农药表
CREATE TABLE pesticide (
  id VARCHAR(64) PRIMARY KEY,
  name VARCHAR(255),
  brand_names JSONB,
  active_ingredient VARCHAR(255),
  chemical_class VARCHAR(100),  -- organophosphate/pyrethroid/etc.
  target_pests JSONB,  -- 针对的病虫害列表
  application_method VARCHAR(50),  -- spray/dusting/granular
  dosage_form VARCHAR(50),  -- liquid/powder/granules
  phitoxicity DECIMAL(3,2),  -- 对人畜毒性
  eco_toxicity DECIMAL(3,2),  -- 生态毒性
  ph_residue_limit DECIMAL(6,4),  -- pH值残留限量
  price_per_kg DECIMAL(10,2),
  manufacturer VARCHAR(255),
  registration_number VARCHAR(100),
  expiry_date DATE,
  banned_regions JSONB,  -- 禁用地区
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 防控方案表
CREATE TABLE control_scheme (
  id VARCHAR(64) PRIMARY KEY,
  field_id VARCHAR(64) REFERENCES field(id),
  pest_disease_id VARCHAR(64) REFERENCES pest_disease(id),
  scheme_type VARCHAR(50),  -- chemical/biological/physical/integrated
  scheme_name VARCHAR(255),
  description TEXT,
  pesticides JSONB,  -- [{pesticideId, dosage, application_method}]
  biological_agents JSONB,  -- 生物防治剂
  physical_methods JSONB,  -- 物理防治方法
  timing_recommendation JSONB,  -- 施药时机
  dosage_per_mu DECIMAL(10,2),  -- 每亩用量
  total_cost DECIMAL(10,2),
  environmental_impact_score DECIMAL(3,2),  -- 0-1, 越低越好
  effectiveness_score DECIMAL(3,2),  -- 0-1, 越高越好
  recommended BOOLEAN,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 防控执行记录表
CREATE TABLE control_execution (
  id SERIAL PRIMARY KEY,
  scheme_id VARCHAR(64) REFERENCES control_scheme(id),
  execution_date DATE,
  executor VARCHAR(255),
  weather_conditions JSONB,  -- 执行时天气
  actual_dosage DECIMAL(10,2),
  actual_cost DECIMAL(10,2),
  labor_hours DECIMAL(6,2),
  equipment_used JSONB,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 防控效果表
CREATE TABLE control_effectiveness (
  id SERIAL PRIMARY KEY,
  execution_id INTEGER REFERENCES control_execution(id),
  evaluation_date DATE,
  disease_severity_before DECIMAL(3,2),
  disease_severity_after DECIMAL(3,2),
  effectiveness_rate DECIMAL(3,2),  -- 防控效果
  crop_yield DECIMAL(10,2),
  yield_loss_percent DECIMAL(4,2),
  notes TEXT,
  evaluator VARCHAR(255),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 法规表
CREATE TABLE pesticide_regulation (
  id VARCHAR(64) PRIMARY KEY,
  region VARCHAR(100),  -- 省/直辖市
  pesticide_id VARCHAR(64) REFERENCES pesticide(id),
  regulation_type VARCHAR(50),  -- banned/restricted/allowed
  effective_date DATE,
  expiration_date DATE,
  max_dosage_per_mu DECIMAL(10,2),
  max_application_times_per_season INTEGER,
  pre_harvest_interval INTEGER,  -- 采收间隔期(天)
  restricted_crops JSONB,
  notes TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**存储方案:**
- **关系型数据库**: PostgreSQL存储农药、防控方案、法规数据
- **图数据库**: Neo4j构建病虫害-农药-法规知识图谱
- **文档数据库**: MongoDB存储防控方案详细描述
- **缓存**: Redis缓存高频查询的农药信息

**数据处理流程:**
1. 接收预警 → 接收病虫害预测Agent的预警信息
2. 知识检索 → 从知识库检索相关的防控知识
3. 方案生成 → 生成多种防控方案(化学、生物、物理、综合)
4. 合规检查 → 检查农药是否符合当地法规
5. 成本估算 → 计算各方案的成本
6. 环境评估 → 评估各方案的环境影响
7. 多目标优化 → 平衡效果、成本、环境目标
8. 方案推荐 → 推荐最优方案并提供备选方案

### 4. 技术设计

**技术选型:**
- **知识图谱**: Neo4j (病虫害-农药-法规知识图谱)
- **优化算法**: NSGA-II (多目标遗传算法), Pymoo
- **推理引擎**: Drools (规则推理)
- **机器学习**: Scikit-learn (方案评估)
- **数据库**: PostgreSQL (主存储), MongoDB (文档存储)
- **缓存**: Redis (热点数据缓存)
- **API框架**: FastAPI (API服务)
- **消息队列**: RabbitMQ (异步任务)

**实现方法:**
```python
# 精准防控核心逻辑
class PrecisionControl:
    def __init__(self):
        self.knowledge_graph = Neo4jClient()
        self.optimizer = MultiObjectiveOptimizer()
        self.regulation_checker = RegulationChecker()
        self.cost_estimator = CostEstimator()
        self.environment_assessor = EnvironmentalAssessor()

    async def generate_control_schemes(self, field_id, disease_id, severity):
        """生成防控方案"""
        # 获取农田与病虫害信息
        field_info = await self.get_field_info(field_id)
        disease_info = await self.get_disease_info(disease_id)
        # 从知识图谱检索防控知识
        control_knowledge = self.knowledge_graph.query("""
            MATCH (d:PestDisease {id: $disease_id})-[:CAN_BE_CONTROLLED_BY]->(m:Method)
            RETURN m
        """, disease_id=disease_id)
        # 生成方案
        schemes = []
        for method in control_knowledge:
            if method['type'] == 'chemical':
                scheme = await self.generate_chemical_scheme(
                    field_info, disease_info, method, severity
                )
            elif method['type'] == 'biological':
                scheme = await self.generate_biological_scheme(
                    field_info, disease_info, method, severity
                )
            elif method['type'] == 'physical':
                scheme = await self.generate_physical_scheme(
                    field_info, disease_info, method, severity
                )
            schemes.append(scheme)
        return schemes

    async def optimize_schemes(self, schemes, objectives, weights):
        """多目标优化"""
        # 定义优化问题
        problem = {
            'variables': schemes,
            'objectives': objectives,
            'weights': weights
        }
        # 运行NSGA-II
        pareto_front = self.optimizer.nsga2(problem)
        # 选择最优方案
        optimal_scheme = self.select_optimal(pareto_front, weights)
        return {
            'optimal_scheme': optimal_scheme,
            'pareto_front': pareto_front,
            'ranking': self.rank_schemes(schemes, objectives)
        }

    async def check_regulation_compliance(self, pesticides, region):
        """法规合规检查"""
        violations = []
        for pesticide in pesticides:
            # 查询当地法规
            regulations = self.knowledge_graph.query("""
                MATCH (p:Pesticide {id: $pesticide_id})
                -[:REGULATED_IN]->(r:Regulation {region: $region})
                RETURN r
            """, pesticide_id=pesticide['id'], region=region)
            # 检查合规性
            for reg in regulations:
                if reg['type'] == 'banned':
                    violations.append({
                        'pesticide': pesticide['name'],
                        'reason': '该农药在' + region + '已被禁用'
                    })
                elif reg['type'] == 'restricted':
                    if pesticide['dosage'] > reg['max_dosage']:
                        violations.append({
                            'pesticide': pesticide['name'],
                            'reason': '用量超过规定上限'
                        })
        return {
            'compliant': len(violations) == 0,
            'violations': violations
        }

    def estimate_cost(self, scheme):
        """成本估算"""
        pesticide_cost = sum(p['price'] * p['dosage'] for p in scheme['pesticides'])
        labor_cost = scheme['labor_hours'] * 50  # 假设人工费50元/小时
        equipment_cost = scheme['equipment_hours'] * 30  # 假设设备费30元/小时
        total_cost = pesticide_cost + labor_cost + equipment_cost
        return total_cost

    def assess_environmental_impact(self, scheme):
        """环境影响评估"""
        # 农药毒性
        pesticide_impact = sum(p['eco_toxicity'] * p['dosage']
                               for p in scheme['pesticides'])
        # 施用频率影响
        frequency_impact = scheme['application_frequency'] * 0.1
        # 环境影响总分(0-1, 越低越好)
        total_impact = (pesticide_impact + frequency_impact) / 2
        return min(total_impact, 1.0)
```

**性能指标:**
- 方案生成响应时间: < 10s
- 多目标优化时间: < 30s (10个方案)
- 法规合规检查准确率: 100%
- 成本估算误差: < 10%
- 环境影响评估准确率: > 80%
- 方案推荐准确率: > 85%
- 系统可用性: > 99.5%
